{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import pickle\n",
    "import graphviz \n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset iris\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# data training\n",
    "X = iris.data\n",
    "\n",
    "# target\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     outlook temperature humidity  windy play\n",
      "0      sunny         hot     high  False   no\n",
      "1      sunny         hot     high   True   no\n",
      "2   overcast         hot     high  False  yes\n",
      "3      rainy        mild     high  False  yes\n",
      "4      rainy        cool   normal  False  yes\n",
      "5      rainy        cool   normal   True   no\n",
      "6   overcast        cool   normal   True  yes\n",
      "7      sunny        mild     high  False   no\n",
      "8      sunny        cool   normal  False  yes\n",
      "9      rainy        mild   normal  False  yes\n",
      "10     sunny        mild   normal   True  yes\n",
      "11  overcast        mild     high   True  yes\n",
      "12  overcast         hot   normal  False  yes\n",
      "13     rainy        mild     high   True   no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "play = pd.read_csv(\"weather.nominal.csv\")\n",
    "print(play);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kNN full-training\n",
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "kNN.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to external file .pkl\n",
    "import pickle\n",
    "kNN_file = open('kNN_full-training.pkl', 'wb')\n",
    "pickle.dump(kNN, kNN_file)\n",
    "kNN_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes full-training\n",
    "NB = GaussianNB()\n",
    "NB.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to external file .pkl\n",
    "import pickle\n",
    "NB_file = open('NB_full-training.pkl', 'wb')\n",
    "pickle.dump(NB, NB_file)\n",
    "NB_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree full-training\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to external file .pkl\n",
    "import pickle\n",
    "DT_file = open('DT_full-training.pkl', 'wb')\n",
    "pickle.dump(DT, DT_file)\n",
    "DT_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree_full-training.png'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display decision tree from learning\n",
    "import graphviz \n",
    "\n",
    "dot_data = tree.export_graphviz(DT, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(filename='tree_full-training',format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decision Tree with Full-Training](tree_full-training.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network Multilayer Perceptron full-training\n",
    "MLP = MLPClassifier()\n",
    "MLP.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to external file .pkl\n",
    "import pickle\n",
    "MLP_file = open('MLP_full-training.pkl', 'wb')\n",
    "pickle.dump(MLP, MLP_file)\n",
    "MLP_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset 90% training and 10% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kNN 90%-training\n",
    "# training data\n",
    "kNN2 = KNeighborsClassifier(n_neighbors=3)\n",
    "kNN2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 90% training with kNN\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 0.9333333333333333\n",
      "\n",
      "Presicion: \n",
      " [1.  1.  0.5]\n",
      "\n",
      "Recall: \n",
      " [1.  0.8 1. ]\n",
      "\n",
      "Confusion Matrix [True→ Predict↓]\n",
      " [[9 0 0]\n",
      " [0 4 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# kNN 90%-training\n",
    "# predict dataset testing with training model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "kNN2_y_predict = kNN2.predict(X_test)\n",
    "\n",
    "# kNN 90%-training\n",
    "# display performance and confusion matrix\n",
    "print('Dataset iris 90% training with kNN')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, kNN2_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, kNN2_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, kNN2_y_predict, average=None))\n",
    "print('\\nConfusion Matrix [True→ Predict↓]\\n', confusion_matrix(y_test, kNN2_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes 90%-training\n",
    "# training data\n",
    "NB2 = GaussianNB()\n",
    "NB2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 90% training with Naive Bayes\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 0.8666666666666667\n",
      "\n",
      "Presicion: \n",
      " [1.  0.8 0. ]\n",
      "\n",
      "Recall: \n",
      " [1.  0.8 0. ]\n",
      "\n",
      "Confusion Matrix [True→ Predict↓]\n",
      " [[9 0 0]\n",
      " [0 4 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes 90%-training\n",
    "# predict dataset testing with training model\n",
    "NB2_y_predict = NB2.predict(X_test)\n",
    "\n",
    "# display performance and confusion matrix\n",
    "print('Dataset iris 90% training with Naive Bayes')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, NB2_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, NB2_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, NB2_y_predict, average=None))\n",
    "print('\\nConfusion Matrix [True→ Predict↓]\\n', confusion_matrix(y_test, NB2_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree 90%-training\n",
    "# training data\n",
    "DT2 = tree.DecisionTreeClassifier()\n",
    "DT2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 90% training with Desicion Tree\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 0.9333333333333333\n",
      "\n",
      "Presicion: \n",
      " [1.  1.  0.5]\n",
      "\n",
      "Recall: \n",
      " [1.  0.8 1. ]\n",
      "\n",
      "Confusion Matrix [True→ Predict↓]\n",
      " [[9 0 0]\n",
      " [0 4 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree 90%-training\n",
    "# predict dataset testing with training model\n",
    "DT2_y_predict = DT2.predict(X_test)\n",
    "\n",
    "# display performance and confusion matrix\n",
    "print('Dataset iris 90% training with Desicion Tree')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, DT2_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, DT2_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, DT2_y_predict, average=None))\n",
    "print('\\nConfusion Matrix [True→ Predict↓]\\n', confusion_matrix(y_test, DT2_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network Multilayer Perceptron 90%-training\n",
    "# training data\n",
    "MLP2 = MLPClassifier()\n",
    "MLP2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 90% training with Neural Network Multilayer Perceptron\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 0.8666666666666667\n",
      "\n",
      "Presicion: \n",
      " [1.         1.         0.33333333]\n",
      "\n",
      "Recall: \n",
      " [1.  0.6 1. ]\n",
      "\n",
      "Confusion Matrix [True→ Predict↓]\n",
      " [[9 0 0]\n",
      " [0 3 2]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Multilayer Perceptron 90%-training\n",
    "# predict dataset testing with training model\n",
    "MLP2_y_predict = MLP2.predict(X_test)\n",
    "\n",
    "# display performance and confusion matrix\n",
    "print('Dataset iris 90% training with Neural Network Multilayer Perceptron')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, MLP2_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, MLP2_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, MLP2_y_predict, average=None))\n",
    "print('\\nConfusion Matrix [True→ Predict↓]\\n', confusion_matrix(y_test, MLP2_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to external file .pkl\n",
    "import pickle\n",
    "kNN2_file = open('kNN_split-90training.pkl', 'wb')\n",
    "pickle.dump(kNN2, kNN2_file)\n",
    "kNN2_file.close()\n",
    "\n",
    "NB2_file = open('NB_split-90training.pkl', 'wb')\n",
    "pickle.dump(NB2, NB2_file)\n",
    "NB2_file.close()\n",
    "\n",
    "DT2_file = open('DT_split-90training.pkl', 'wb')\n",
    "pickle.dump(DT2, DT2_file)\n",
    "DT2_file.close()\n",
    "\n",
    "MLP2_file = open('MLP_split-90training.pkl', 'wb')\n",
    "pickle.dump(MLP2, MLP2_file)\n",
    "MLP2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 10-Fold Cross Validation\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Iterasi  1\n",
      "kNN : Accuracy: 0.9333333333333333 Presicion: [1.         1.         0.85714286] Recall: [1.   0.75 1.  ]\n",
      "NB  : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 0.8666666666666667 Presicion: [1.         0.75       0.83333333] Recall: [1.         0.75       0.83333333]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "\n",
      "Iterasi  2\n",
      "kNN : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "NB  : Accuracy: 0.9333333333333333 Presicion: [1.         0.83333333 1.        ] Recall: [1.   1.   0.75]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "\n",
      "Iterasi  3\n",
      "kNN : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "NB  : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "\n",
      "Iterasi  4\n",
      "kNN : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "NB  : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "\n",
      "Iterasi  5\n",
      "kNN : Accuracy: 0.9333333333333333 Presicion: [1.    1.    0.875] Recall: [1.  0.8 1. ]\n",
      "NB  : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 0.8666666666666667 Presicion: [1.         0.8        0.85714286] Recall: [1.         0.8        0.85714286]\n",
      "DTL : Accuracy: 0.9333333333333333 Presicion: [1.    1.    0.875] Recall: [1.  0.8 1. ]\n",
      "\n",
      "Iterasi  6\n",
      "kNN : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "NB  : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "\n",
      "Iterasi  7\n",
      "kNN : Accuracy: 0.8 Presicion: [1.         0.77777778 0.66666667] Recall: [1.    0.875 0.5  ]\n",
      "NB  : Accuracy: 0.7333333333333333 Presicion: [1.   0.75 0.5 ] Recall: [1.   0.75 0.5 ]\n",
      "DTL : Accuracy: 0.8 Presicion: [1.         0.85714286 0.6       ] Recall: [1.   0.75 0.75]\n",
      "DTL : Accuracy: 0.9333333333333333 Presicion: [1.  1.  0.8] Recall: [1.    0.875 1.   ]\n",
      "\n",
      "Iterasi  8\n",
      "kNN : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "NB  : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "\n",
      "Iterasi  9\n",
      "kNN : Accuracy: 0.9333333333333333 Presicion: [1.         0.83333333 1.        ] Recall: [1.         1.         0.85714286]\n",
      "NB  : Accuracy: 0.9333333333333333 Presicion: [1.         0.83333333 1.        ] Recall: [1.         1.         0.85714286]\n",
      "DTL : Accuracy: 0.9333333333333333 Presicion: [1.         0.83333333 1.        ] Recall: [1.         1.         0.85714286]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "\n",
      "Iterasi  10\n",
      "kNN : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "NB  : Accuracy: 0.9333333333333333 Presicion: [1.  1.  0.8] Recall: [1.         0.83333333 1.        ]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n",
      "DTL : Accuracy: 1.0 Presicion: [1. 1. 1.] Recall: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#10-Fold Cross Validation\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "\n",
    "y = iris.target\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "print('Dataset iris 10-Fold Cross Validation')\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "i=1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    print('\\nIterasi ', i)\n",
    "    i = i+1\n",
    "    \n",
    "    # kNN 10-Fold Cross Validation\n",
    "    kNN3 = KNeighborsClassifier(n_neighbors=3)\n",
    "    kNN3.fit(X_train,y_train)\n",
    "    \n",
    "    # display performance Decision Tree 10-Fold Cross Validation\n",
    "    kNN3_y_predict = kNN3.predict(X_test)\n",
    "    print('kNN : Accuracy:', accuracy_score(y_test, kNN3_y_predict), 'Presicion:', precision_score(y_test, kNN3_y_predict, average=None), 'Recall:', recall_score(y_test, kNN3_y_predict, average=None))\n",
    "    \n",
    "    #Naive Bayes 10-Fold Cross Validation\n",
    "    NB3 = GaussianNB()\n",
    "    NB3.fit(X_train,y_train)\n",
    "    \n",
    "    #display performance Naive Bayes 10-Fold Cross Validation\n",
    "    NB3_y_predict = NB3.predict(X_test)\n",
    "    print('NB  : Accuracy:', accuracy_score(y_test, NB3_y_predict), 'Presicion:', precision_score(y_test, NB3_y_predict, average=None), 'Recall:', recall_score(y_test, NB3_y_predict, average=None))\n",
    "    \n",
    "    #Decision Tree 10-Fold Cross Validation\n",
    "    DT3 = tree.DecisionTreeClassifier()\n",
    "    DT3.fit(X_train,y_train)\n",
    "    \n",
    "    #display performance Decision Tree 10-Fold Cross Validation\n",
    "    DT3_y_predict = DT3.predict(X_test)\n",
    "    print('DTL : Accuracy:', accuracy_score(y_test, DT3_y_predict), 'Presicion:', precision_score(y_test, DT3_y_predict, average=None), 'Recall:', recall_score(y_test, DT3_y_predict, average=None))\n",
    "    \n",
    "    #Neural Network Multilayer Perceptron 10-Fold Cross Validation\n",
    "    MLP3 = MLPClassifier()\n",
    "    MLP3.fit(X_train,y_train)\n",
    "    \n",
    "    #display performance Neural Network Multilayer Perceptron 10-Fold Cross Validation\n",
    "    MLP3_y_predict = MLP3.predict(X_test)\n",
    "    print('DTL : Accuracy:', accuracy_score(y_test, MLP3_y_predict), 'Presicion:', precision_score(y_test, MLP3_y_predict, average=None), 'Recall:', recall_score(y_test, MLP3_y_predict, average=None))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create new instance\n",
    "X_new = np.array([[7.1, 4.5, 6.0, 2.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] = ['virginica']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#classification of new instance\n",
    "file = open('kNN_full-training.pkl', 'rb')\n",
    "kNN = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "#kNN full-training\n",
    "class_id = kNN.predict(X_new)\n",
    "print(class_id, '=', iris.target_names[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] = ['virginica']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#classification of new instance\n",
    "file = open('NB_full-training.pkl', 'rb')\n",
    "NB = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "#Naive Bayes full-training\n",
    "class_id = NB.predict(X_new)\n",
    "print(class_id, '=', iris.target_names[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] = ['virginica']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#classification of new instance\n",
    "file = open('DT_full-training.pkl', 'rb')\n",
    "DT = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "#Decision Tree full-training\n",
    "class_id = DT.predict(X_new)\n",
    "print(class_id, '=', iris.target_names[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] = ['virginica']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#classification of new instance\n",
    "file = open('MLP_full-training.pkl', 'rb')\n",
    "MLP = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "#Neural Network Multilayer Perceptron full-training\n",
    "class_id = MLP.predict(X_new)\n",
    "print(class_id, '=', iris.target_names[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
