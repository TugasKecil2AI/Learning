{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import pickle\n",
    "import graphviz \n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset iris\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# data training\n",
    "X = iris.data\n",
    "\n",
    "# target\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kNN full-training\n",
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "kNN.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to external file .pkl\n",
    "import pickle\n",
    "kNN_file = open('kNN_full-training.pkl', 'wb')\n",
    "pickle.dump(kNN, kNN_file)\n",
    "kNN_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes full-training\n",
    "NB = GaussianNB()\n",
    "NB.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree full-training\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9660bbaf475f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# display decision tree from learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m dot_data = tree.export_graphviz(DT, out_file=None, \n\u001b[1;32m      5\u001b[0m                          \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "# display decision tree from learning\n",
    "import graphviz \n",
    "\n",
    "dot_data = tree.export_graphviz(DT, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network Multilayer Perceptron full-training\n",
    "MLP = MLPClassifier()\n",
    "MLP.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset 90% training and 10% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kNN 90%-training\n",
    "# training data\n",
    "kNN2 = KNeighborsClassifier(n_neighbors=3)\n",
    "kNN2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 90% training with kNN\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 1.0\n",
      "\n",
      "Presicion: \n",
      " [1. 1. 1.]\n",
      "\n",
      "Recall: \n",
      " [1. 1. 1.]\n",
      "\n",
      "Confusion Matrix [True→ Predict↓]\n",
      " [[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "# kNN 90%-training\n",
    "# predict dataset testing with training model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "kNN2_y_predict = kNN2.predict(X_test)\n",
    "\n",
    "# kNN 90%-training\n",
    "# display performance and confusion matrix\n",
    "print('Dataset iris 90% training with kNN')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, kNN2_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, kNN2_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, kNN2_y_predict, average=None))\n",
    "print('\\nConfusion Matrix [True→ Predict↓]\\n', confusion_matrix(y_test, kNN2_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes 90%-training\n",
    "# training data\n",
    "NB2 = GaussianNB()\n",
    "NB2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 90% training with Naive Bayes\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 1.0\n",
      "\n",
      "Presicion: \n",
      " [1. 1. 1.]\n",
      "\n",
      "Recall: \n",
      " [1. 1. 1.]\n",
      "\n",
      "Confusion Matrix [True→ Predict↓]\n",
      " [[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes 90%-training\n",
    "# predict dataset testing with training model\n",
    "NB2_y_predict = NB2.predict(X_test)\n",
    "\n",
    "# display performance and confusion matrix\n",
    "print('Dataset iris 90% training with Naive Bayes')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, NB2_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, NB2_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, NB2_y_predict, average=None))\n",
    "print('\\nConfusion Matrix [True→ Predict↓]\\n', confusion_matrix(y_test, NB2_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree 90%-training\n",
    "# training data\n",
    "DT2 = tree.DecisionTreeClassifier()\n",
    "DT2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 90% training with Desicion Tree\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 0.9333333333333333\n",
      "\n",
      "Presicion: \n",
      " [1.         0.83333333 1.        ]\n",
      "\n",
      "Recall: \n",
      " [1.         1.         0.83333333]\n",
      "\n",
      "Confusion Matrix [True→ Predict↓]\n",
      " [[4 0 0]\n",
      " [0 5 0]\n",
      " [0 1 5]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree 90%-training\n",
    "# predict dataset testing with training model\n",
    "DT2_y_predict = DT2.predict(X_test)\n",
    "\n",
    "# display performance and confusion matrix\n",
    "print('Dataset iris 90% training with Desicion Tree')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, DT2_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, DT2_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, DT2_y_predict, average=None))\n",
    "print('\\nConfusion Matrix [True→ Predict↓]\\n', confusion_matrix(y_test, DT2_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network Multilayer Perceptron 90%-training\n",
    "# training data\n",
    "MLP2 = MLPClassifier()\n",
    "MLP2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris 90% training with Neural Network Multilayer Perceptron\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 0.9333333333333333\n",
      "\n",
      "Presicion: \n",
      " [1.         1.         0.85714286]\n",
      "\n",
      "Recall: \n",
      " [1.  0.8 1. ]\n",
      "\n",
      "Confusion Matrix [True→ Predict↓]\n",
      " [[4 0 0]\n",
      " [0 4 1]\n",
      " [0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Multilayer Perceptron 90%-training\n",
    "# predict dataset testing with training model\n",
    "MLP2_y_predict = MLP2.predict(X_test)\n",
    "\n",
    "# display performance and confusion matrix\n",
    "print('Dataset iris 90% training with Neural Network Multilayer Perceptron')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, MLP2_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, MLP2_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, MLP2_y_predict, average=None))\n",
    "print('\\nConfusion Matrix [True→ Predict↓]\\n', confusion_matrix(y_test, MLP2_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     outlook temperature humidity  windy play\n",
      "0      sunny         hot     high  False   no\n",
      "1      sunny         hot     high   True   no\n",
      "2   overcast         hot     high  False  yes\n",
      "3      rainy        mild     high  False  yes\n",
      "4      rainy        cool   normal  False  yes\n",
      "5      rainy        cool   normal   True   no\n",
      "6   overcast        cool   normal   True  yes\n",
      "7      sunny        mild     high  False   no\n",
      "8      sunny        cool   normal  False  yes\n",
      "9      rainy        mild   normal  False  yes\n",
      "10     sunny        mild   normal   True  yes\n",
      "11  overcast        mild     high   True  yes\n",
      "12  overcast         hot   normal  False  yes\n",
      "13     rainy        mild     high   True   no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "play = pd.read_csv(\"weather.nominal.csv\")\n",
    "print(play);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10-Fold Cross Validation\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "\n",
    "y = iris.target\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes 10-Fold Cross Validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB3 = GaussianNB()\n",
    "NB3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris Naive Bayes 10-Fold Cross Validation\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 1.0\n",
      "\n",
      "Presicion: \n",
      " [1.]\n",
      "\n",
      "Recall: \n",
      " [1.]\n"
     ]
    }
   ],
   "source": [
    "#display performance Naive Bayes 10-Fold Cross Validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "NB3_y_predict = NB3.predict(X_test)\n",
    "print('Dataset iris Naive Bayes 10-Fold Cross Validation')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, NB3_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, NB3_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, NB3_y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree 10-Fold Cross Validation\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT3 = tree.DecisionTreeClassifier()\n",
    "DT3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris Decision Tree 10-Fold Cross Validation\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 1.0\n",
      "\n",
      "Presicion: \n",
      " [1.]\n",
      "\n",
      "Recall: \n",
      " [1.]\n"
     ]
    }
   ],
   "source": [
    "# display performance Decision Tree 10-Fold Cross Validation\n",
    "DT3_y_predict = DT3.predict(X_test)\n",
    "print('Dataset iris Decision Tree 10-Fold Cross Validation')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, DT3_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, DT3_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, DT3_y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kNN 10-Fold Cross Validation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kNN3 = KNeighborsClassifier(n_neighbors=3)\n",
    "kNN3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris Decision Tree 10-Fold Cross Validation\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 1.0\n",
      "\n",
      "Presicion: \n",
      " [1.]\n",
      "\n",
      "Recall: \n",
      " [1.]\n"
     ]
    }
   ],
   "source": [
    "# display performance Decision Tree 10-Fold Cross Validation\n",
    "kNN3_y_predict = kNN3.predict(X_test)\n",
    "print('Dataset iris Decision Tree 10-Fold Cross Validation')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, kNN3_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, kNN3_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, kNN3_y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network MLP 10-Fold Cross Validation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP3 = MLPClassifier()\n",
    "MLP3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iris Decision Tree 10-Fold Cross Validation\n",
      "\n",
      "Attributes:\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy: \n",
      " 1.0\n",
      "\n",
      "Presicion: \n",
      " [1.]\n",
      "\n",
      "Recall: \n",
      " [1.]\n"
     ]
    }
   ],
   "source": [
    "# display performance Neural Network MLP 10-Fold Cross Validation\n",
    "MLP3_y_predict = MLP3.predict(X_test)\n",
    "print('Dataset iris Decision Tree 10-Fold Cross Validation')\n",
    "\n",
    "print('\\nAttributes:\\n', iris.target_names)\n",
    "print('\\nAccuracy: \\n', accuracy_score(y_test, MLP3_y_predict))\n",
    "print('\\nPresicion: \\n', precision_score(y_test, MLP3_y_predict, average=None))\n",
    "print('\\nRecall: \\n', recall_score(y_test, MLP3_y_predict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new instance\n",
    "X_new = [7.1, 4.5, 6.0, 2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification of new instance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
